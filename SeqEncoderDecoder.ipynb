{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_lstm import LSTM,entangledLSTMCell,LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOS_token = 0\n",
    "# EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0\n",
    "    \n",
    "    def index_words(self, sentence):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            self.index_word(word)\n",
    "    \n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1  \n",
    "            \n",
    "    def filterRareWords(self, vocabularySize = 45000):\n",
    "        sorted_words = sorted(list(self.word2count.items()), \n",
    "                              key = lambda x: -x[1])\n",
    "        most_frequent_words = [w for (w, c) in sorted_words[:vocabularySize]]\n",
    "        self.word2index = {w: (index + 1) for (index, w) in enumerate(most_frequent_words)}\n",
    "        self.word2index[\"[EOS]\"] = 0\n",
    "        self.word2index[\"[SOS]\"] = len(self.word2index)\n",
    "        self.word2index[\"[UNK]\"] = len(self.word2index)\n",
    "        self.index2word = {index: w for (w, index) in self.word2index.items()}\n",
    "        self.vocabulary = {'word2id': self.word2index, 'id2word': self.index2word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = re.sub(r\"([.!?])\", r\"\\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArticle(fileName):\n",
    "#     print(\"reading articles...\")\n",
    "    \n",
    "    f = open(fileName)\n",
    "    contentFlag = True\n",
    "\n",
    "    rawLine = \"\"\n",
    "    \n",
    "    rawLine = f.read()\n",
    "    sent_tokenize_list = sent_tokenize(rawLine)\n",
    "    \n",
    "    if len(sent_tokenize_list) > 1:\n",
    "        reservedSents = sent_tokenize_list[0]+\"\\t\"+sent_tokenize_list[1]\n",
    "    else:\n",
    "        if len(sent_tokenize_list) == 1:\n",
    "            reservedSents = sent_tokenize_list[0]\n",
    "        else:\n",
    "            contentFlag = False\n",
    "            print(\"no article content\", fileName)\n",
    "            return rawLine, False\n",
    "#             reservedSents = sent_tokenize_list[0]\n",
    "#     print(reservedSents)\n",
    "    rawLine = normalize_string(reservedSents).strip()\n",
    "#     print(\"rawLine\\t\", rawLine)\n",
    "    f.close()\n",
    "    return rawLine, contentFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCaption(fileName):\n",
    "#     print(\"reading captions...\")\n",
    "    contentFlag = True\n",
    "    f = open(fileName)\n",
    "    rawLine = f.read()\n",
    "#     print(\"caption\\t\", rawLine)\n",
    "    rawLine = normalize_string(rawLine).strip()\n",
    "    if len(rawLine) == 0:\n",
    "        contentFlag = False\n",
    "    \n",
    "    f.close()\n",
    "    return rawLine, contentFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArticleCaptionPairs(vggfeatures, articleDirName, captionDirName, pairs):\n",
    "    \n",
    "    for fileName in os.listdir(articleDirName):\n",
    "        if fileName.endswith(\".txt\"):\n",
    "            articleFileName = os.path.join(articleDirName, fileName)\n",
    "            captionFileName = os.path.join(captionDirName, fileName)\n",
    "            if not os.path.isfile(captionFileName):\n",
    "                continue\n",
    "#             print(articleFileName)\n",
    "            articleContent, contentFlag = readArticle(articleFileName)\n",
    "            if contentFlag == False:\n",
    "                continue\n",
    "                \n",
    "            captionContent, contentFlag = readCaption(captionFileName)  \n",
    "            if contentFlag == False:\n",
    "                continue\n",
    "            \n",
    "            articleName = fileName.split(\".\")[0]\n",
    "            if articleName not in list(vggfeatures.keys()):\n",
    "                continue\n",
    "                \n",
    "            articleImgFeature = vggfeatures[articleName]\n",
    "            \n",
    "            articleCaptionPair = (articleContent, captionContent, articleImgFeature)\n",
    "            pairs.append(articleCaptionPair)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(articleCaptionLang, articleDirName, captionDirName, vggFileName):\n",
    "    \n",
    "    pairs = []\n",
    "    f_image=open(vggFileName,\"rb\")\n",
    "    vgg_features=dict(pickle.load(f_image))\n",
    "    readArticleCaptionPairs(vgg_features, articleDirName, captionDirName, pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        articleCaptionLang.index_words(pair[0])\n",
    "        articleCaptionLang.index_words(pair[1])\n",
    "    \n",
    "#     articleCaptionLang.filterRareWords()\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(articleCaptionLang, articleDirName, captionDirName, vggFileName, articleDirName1, captionDirName1, vggFileName1):\n",
    "    \n",
    "    pairs = []\n",
    "    f_image=open(vggFileName,\"rb\")\n",
    "    vgg_features=dict(pickle.load(f_image))\n",
    "    readArticleCaptionPairs(vgg_features, articleDirName, captionDirName, pairs)\n",
    "    \n",
    "    f_image1=open(vggFileName1,\"rb\")\n",
    "    vgg_features1=dict(pickle.load(f_image1))\n",
    "    readArticleCaptionPairs(vgg_features1, articleDirName1, captionDirName1, pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        articleCaptionLang.index_words(pair[0])\n",
    "        articleCaptionLang.index_words(pair[1])\n",
    "    \n",
    "#     articleCaptionLang.filterRareWords()\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizeWordDistribution(articleCaptionLang):\n",
    "    sorted_words = sorted(list(articleCaptionLang.word2count.items()), \n",
    "                              key = lambda x: -x[1])\n",
    "    totalVocSize = len(sorted_words)\n",
    "    print(\"totalVocSize\\t\", totalVocSize)\n",
    "    xList = []\n",
    "    yList = []\n",
    "    \n",
    "    for wordIndex in range(totalVocSize):\n",
    "#         print(wordIndex)\n",
    "        xList.append(wordIndex)\n",
    "        yList.append(articleCaptionLang.word2count[sorted_words[wordIndex][0]])\n",
    "    \n",
    "    print(np.mean(yList))\n",
    "    print(yList[42000])\n",
    "    plt.plot(xList, yList)\n",
    "    plt.show()\n",
    "    \n",
    "#     for word in sorted_words:\n",
    "#         xList.append()\n",
    "#     most_frequent_words = [w for (w, c) in sorted_words]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleCaptionLang = Lang(\"articleCaption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleDirName = \"./data/IND-articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleDirName1 = \"./data/WP-articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionDirName = \"./data/IND-captions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionDirName1 = \"./data/WP-captions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggFileName = \"./data/vggfeatures-IND.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggFileName1 = \"./data/vggfeatures-WP.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no article content ./data/IND-articles/045a44bfa5deb73700ece6f3e67898d05207cc4f.txt\n",
      "no article content ./data/IND-articles/bc2eb6fe5061212ad8a136d6341a7ac3f89348ed.txt\n",
      "no article content ./data/IND-articles/290f1bc094cde2bdc8697d27962f5932a84691e8.txt\n",
      "no article content ./data/IND-articles/484458ea7d2713120a48df395f199ff2520c12c0.txt\n",
      "no article content ./data/IND-articles/4c6bbd83dac70c4f8cbd2168d2025db0c414589a.txt\n",
      "no article content ./data/IND-articles/bf760baa0947463c2fb2e0d6b64907557be14db0.txt\n",
      "no article content ./data/IND-articles/21560277b4d140955e3a2d442c0856f1225636c6.txt\n",
      "no article content ./data/IND-articles/2c5f5f84827655fe27474c598c60192e0e33a16b.txt\n",
      "no article content ./data/IND-articles/09fa9ec8fe536c3e72b7f0d0b3c1af95502c8103.txt\n",
      "no article content ./data/IND-articles/5fc2d9471637d9491c9c965770a5c42e950caa29.txt\n",
      "no article content ./data/IND-articles/25f01d519405575bd9b9f7a5bff58b267a0f37d9.txt\n",
      "no article content ./data/IND-articles/ac2986d9e1cee80b6e566b8eb8cc1139998217ac.txt\n",
      "no article content ./data/IND-articles/4a5bfb2f4ed89eb95737cc81b37b87d2e3fb1e01.txt\n",
      "no article content ./data/IND-articles/79200c09c922948df5fdc1a00005eded6f446932.txt\n",
      "no article content ./data/IND-articles/c53e5c876d25938370431b7ec4a573de04000cd4.txt\n",
      "no article content ./data/IND-articles/bb75da3649fe23341265dab2b0617b794508ef1d.txt\n",
      "no article content ./data/IND-articles/913f7dd732d9aa067aefa013d4ee23284826273a.txt\n",
      "no article content ./data/IND-articles/aee1c53345e6aa675085212fea8d7e5f07481dcc.txt\n",
      "no article content ./data/IND-articles/2cb6e5c6a5c2ab7aa44f3e386977be9a8489f7bf.txt\n"
     ]
    }
   ],
   "source": [
    "pairs=prepareData(articleCaptionLang, articleDirName, captionDirName, vggFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=prepareData(articleCaptionLang, articleDirName, captionDirName, vggFileName, articleDirName1, captionDirName1, vggFileName1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleCaptionLang.filterRareWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalVocSize\t 44554\n",
      "30.7574179647\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAFkCAYAAADsVgtLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWTCdjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7b714b240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeWordDistribution(articleCaptionLang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Investors in World Wrestling Entertainment were dealt a blow this week after stocks fell at the end of the st annual WrestleMania blowout. Shares rallied a little in after hours trading after falling to . at close on Monday.', 'WWE stock slammed despite record breaking WrestleMania event', array([-0.        ,  4.16756058, -0.        , ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Radiohead s previously unreleased song Spooks is set to feature in Paul Thomas Anderson s forthcoming film Inherent Vice the first adaptation of a Thomas Pynchon novel. The instrumental surf rock track is included on lead guitarist Jonny Greenwood s soundtrack for the comedy crime drama about a drug addled LA detective investigating the mysterious disappearance of his ex girlfriend in the Seventies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(word_tokenize(a.lower())))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    ids = []\n",
    "    for w in word_tokenize(sentence.lower()):\n",
    "        if w not in lang.word2index.keys():\n",
    "            ids.append(lang.word2index['[UNK]'])\n",
    "        else:\n",
    "            ids.append(lang.word2index[w])\n",
    "            \n",
    "    ids.insert(0, lang.word2index['[SOS]'])\n",
    "    ids.append(lang.word2index['[EOS]'])\n",
    "\n",
    "    return ids\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(articleCaptionLang, pair):\n",
    "    input_variable = variable_from_sentence(articleCaptionLang, pair[0])\n",
    "    target_variable = variable_from_sentence(articleCaptionLang, pair[1])\n",
    "   \n",
    "    image_feature = pair[2]\n",
    "    if USE_CUDA:\n",
    "        image_feature = image_feature.cuda()\n",
    "    return (input_variable, target_variable, image_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pair = variables_from_pair(articleCaptionLang, random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, img_size, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(img_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, img, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        embedded[0] = self.linear(img).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, entangled_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "       \n",
    "        self.gru = LSTM(entangledLSTMCell, input_size, hidden_size , factor_size=hidden_size, entangled_size=entangled_size, batch_first = False)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden, tagFeatures):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        \n",
    "        output, hidden =  self.gru(embedded, hx=(hidden,hidden), entangler=tagFeatures)\n",
    "        \n",
    "#         output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=MAX_LENGTH):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_image=open('data/vggfeatures-IND.pickle',\"rb\")\n",
    "vgg_features=pickle.load(f_image)\n",
    "f_image=open('data/vggfeatures-WP.pickle',\"rb\")\n",
    "vgg_features1=pickle.load(f_image)\n",
    "vgg_features=dict(vgg_features, **vgg_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_image=open('data/vggfeatures-IND.pickle',\"rb\")\n",
    "vgg_features1=dict(pickle.load(f_image))\n",
    "# vgg_features=dict(vgg_features, **vgg_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"b83d8680253561e90705ce42af8d0f4deb33a286.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b83d8680253561e90705ce42af8d0f4deb33a286\n"
     ]
    }
   ],
   "source": [
    "aName = a.split(\".\")[0]\n",
    "print(aName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.        ,  1.19822621, ..., -0.        ,\n",
       "       -0.        , -0.        ], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_features1[aName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b83d8680253561e90705ce42af8d0f4deb33a286\n",
      "[-0.         -0.          1.19822621 ..., -0.         -0.         -0.        ]\n",
      "8ca8cb29e5df5932aff18d1143b05cd0262b6b6e\n",
      "[ 0.34955347 -0.         -0.         ..., -0.         -0.          1.24109232]\n",
      "a395523c9b5dc5b39bb505171763121fe72a49b2\n",
      "[ 2.11561298 -0.         -0.         ..., -0.          1.64500403\n",
      "  0.26022199]\n",
      "3ca1e6745c41d1424d54f6b1e7a7c87f40cd3852\n",
      "[-0.         -0.         -0.         ..., -0.         -0.          0.03353977]\n",
      "c48b838b44549a6191bdaff4f2161a5247f8e6bf\n",
      "[-0.        -0.        -0.        ..., -0.         1.0676744 -0.       ]\n",
      "08268aa056c9ae548a6e6eab05550b6a63b04315\n",
      "[-0.         -0.         -0.         ..., -0.         -0.          0.15161002]\n",
      "784817a62af57c03f7863c213e2a6e753339527a\n",
      "[-0.         -0.         -0.         ..., -0.         -0.          2.45507145]\n",
      "0f1f579ec0898852dec60c7c0031dfc0cc9e3afd\n",
      "[-0. -0. -0. ..., -0. -0. -0.]\n",
      "1bed0d947a56b60a9060fd616b2ecd1e9e5a5b2b\n",
      "[-0. -0. -0. ..., -0. -0. -0.]\n",
      "58e72f733d7e8fd1b08da189cce560c6b80c9e26\n",
      "[ 1.55758834 -0.         -0.         ..., -0.          0.58582628 -0.        ]\n"
     ]
    }
   ],
   "source": [
    "vggFeaturesKeyList = list(vgg_features.keys())\n",
    "for i in range(10):\n",
    "    vggFeatureKey = vggFeaturesKeyList[i]\n",
    "    print(vggFeatureKey)\n",
    "    print(vgg_features[vggFeatureKey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(articleCaptionLang, input_variable, target_variable, vggFeature, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "    \n",
    "     # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden, vggFeature)\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([[articleCaptionLang.word2index['[SOS]']]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "        \n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            decoder_input = target_variable[di]\n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output[0], target_variable[di])\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "                \n",
    "            if ni==articleCaptionLang.word2index['[EOS]']:\n",
    "                break\n",
    "                \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0]/target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return \"%dm %ds\"%(m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now-since\n",
    "    es = s/percent\n",
    "    rs = es - s\n",
    "    \n",
    "    return \"%s (-%s)\"%(as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = \"general\"\n",
    "hidden_size = 500\n",
    "n_layers = 4\n",
    "dropout_p = 0.05\n",
    "entangled_size = 4096\n",
    "\n",
    "encoder = EncoderRNN(articleCaptionLang.n_words, hidden_size, entangled_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, articleCaptionLang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    \n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50000\n",
    "plot_every = 800\n",
    "print_every = 400\n",
    "\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0\n",
    "plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190\n"
     ]
    }
   ],
   "source": [
    "totalPairNum = len(pairs)\n",
    "\n",
    "print(totalPairNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(pairs)\n",
    "trainingNum = int(totalPairNum*0.8)\n",
    "trainingPairs = pairs[:trainingNum]\n",
    "testingPairs = pairs[trainingNum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /home/soumith/local/builder/wheel/pytorch-src/torch/lib/THC/generic/THCTensorCopy.c:18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-eebbd9aa0cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvggFeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticleCaptionLang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvggFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-dcef733683b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(articleCaptionLang, input_variable, target_variable, vggFeature, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Run words through encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvggFeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marticleCaptionLang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'[SOS]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-443378948886>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inputs, hidden, tagFeatures)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentangler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtagFeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         output, hidden = self.gru(embedded, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/zf15/rc7ne/Code/CV/CVProject/util_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, length, hx, entangler)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /home/soumith/local/builder/wheel/pytorch-src/torch/lib/THC/generic/THCTensorCopy.c:18"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "    training_pair = variables_from_pair(articleCaptionLang, random.choice(trainingPairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "    vggFeature = training_pair[2]\n",
    "    \n",
    "    loss = train(articleCaptionLang, input_variable, target_variable, vggFeature, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    \n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    \n",
    "    if epoch == 0:continue\n",
    "        \n",
    "    if epoch%print_every == 0:\n",
    "        print_loss_avg = print_loss_total /print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = \"%s (%d %d %%) %.4f\"%(time_since(start, epoch/n_epochs), epoch, epoch/n_epochs*100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch%plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a5038ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a502eb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    \n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(articleCaptionLang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[articleCaptionLang.word2index['[SOS]']]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "#         decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == articleCaptionLang.word2index['[EOS]']:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(articleCaptionLang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /home/soumith/local/builder/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-13c73f52e069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-753c07be8ff2>\u001b[0m in \u001b[0;36mevaluate_randomly\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-0f247e9bc110>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Run through encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Create starting vectors for decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-845e12850e3c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inputs, hidden)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mdropout_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/zf15/rc7ne/anaconda3/lib/python3.5/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    245\u001b[0m         num_weights = get_num_weights(\n\u001b[1;32m    246\u001b[0m             handle, fn.rnn_desc, fn.x_descs[0], fn.datatype)\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_weight_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /home/soumith/local/builder/wheel/pytorch-src/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
